{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEnT4bZnu5jQ"
   },
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "-ZlMuBGau5ji",
    "outputId": "5da0cfb2-cb8b-4e74-b855-c6f5ee880513"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "tile_size = 19\n",
    "feature_count = 3\n",
    "input_count = tile_size * tile_size * feature_count\n",
    "DATA_FILES_ROOT = \"DataFiles/\"\n",
    "PRED_FILES_ROOT = \"Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "loading 9000. file\n",
      "loading 10000. file\n",
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n"
     ]
    }
   ],
   "source": [
    "def load_data(dataset_name: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load data files for the given dataset.\n",
    "\n",
    "    :param dataset_name: Name of the data set.\n",
    "    :return: np.array of data files in (input_count, ) shape.\n",
    "    \"\"\"\n",
    "    data_path = DATA_FILES_ROOT + dataset_name + \"_data/\"\n",
    "    data_files = os.listdir(data_path)\n",
    "    data_array = [None] * len(data_files)\n",
    "    for i, file in enumerate(data_files):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"loading {i}. file\")\n",
    "        data = np.loadtxt(data_path + file, skiprows=1, delimiter=',')\n",
    "        data_array[i] = data.flatten()\n",
    "    return np.array(data_array)\n",
    "\n",
    "\n",
    "def load_labels(dataset_name: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load data labels for the given dataset.\n",
    "\n",
    "    :param dataset_name: Name of the data set.\n",
    "    :return: np.array of the data labels.\n",
    "    \"\"\"\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    labels_array = [None] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        labels_array[i] = label[2]\n",
    "    return np.array(labels_array)\n",
    "\n",
    "def load_datasets(datasets: list) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "    Load both the input data vectors and labels of the datasets with the given names.\n",
    "\n",
    "    :param datasets: List with the dataset names.\n",
    "    :return: tuple of np.arrays, one with the input vectors, second with labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = np.array([])\n",
    "    for dataset in datasets:\n",
    "        if (len(data) == 0):\n",
    "            data = load_data(dataset)\n",
    "        else:\n",
    "            data = np.concatenate((data, load_data(dataset)), axis=0)\n",
    "        labels = np.concatenate((labels, load_labels(dataset)), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "datasets = [\"fruit_02\", \"fruit_03\", \"fruit_04\"]\n",
    "data, labels = load_datasets(datasets)\n",
    "print(\"done loading datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26913, 1080)\n",
      "(26913,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "uqJeDH0Jgq3u",
    "outputId": "3c13268c-c4a7-4421-e61f-54dfdb4dee1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18839\n",
      "18561.0\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(train_X))\n",
    "print(np.sum(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhchzYAxKNou"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7ZElIFH8o63W",
    "outputId": "2c9807df-0ec1-4283-d0d6-d7a3b3fca88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train accuracy: 1.0\n",
      "Actual percentage of true points: 0.9852433780986252\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(C=1000, gamma=1/10000, kernel='rbf')\n",
    "#model_svm = svm.SVC(kernel='rbf')\n",
    "model_svm.fit(train_X, train_y)\n",
    "\n",
    "print(f\"SVM Train accuracy: {model_svm.score(train_X, train_y)}\")\n",
    "print(f\"Actual percentage of true points: {np.sum(train_y)/len(train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.99140127 0.99124204 0.9906036 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross validation scores: {cross_val_score(model_svm, train_X, train_y, cv=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SVM Test accuracy: {model_svm.score(test_X, test_y)}\")\n",
    "print(f\"Actual percentage of true points: {np.sum(test_y)/len(test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  166   112]\n",
      " [   53 18508]]\n",
      "0.9939849624060151\n",
      "0.9971445504013793\n"
     ]
    }
   ],
   "source": [
    "train_y_prediction = cross_val_predict(model_svm, train_X, train_y, cv=3)\n",
    "confusion = confusion_matrix(train_y, train_y_prediction)\n",
    "precision = precision_score(train_y, train_y_prediction)\n",
    "recall = recall_score(train_y, train_y_prediction)\n",
    "\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=20, max_depth=10)\n",
    "model_rfc.fit(train_X, train_y)\n",
    "\n",
    "print(f\"RFC Train accuracy: {model_svm.score(train_X, train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.99442675 0.99458599 0.99331104]\n",
      "RFC Test accuracy: 0.9946742630666336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross validation scores: {cross_val_score(model_rfc, train_X, train_y, cv=3)}\")\n",
    "print(f\"RFC Test accuracy: {model_rfc.score(test_X, test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "loading 9000. file\n",
      "loading 10000. file\n",
      "loading 11000. file\n",
      "loading 12000. file\n",
      "Made 1936 mistakes!\n",
      "There were total of 2006 zeroes!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_indices(dataset_name: str) -> list:\n",
    "    \"\"\"\n",
    "    Load point ids for the given dataset.\n",
    "\n",
    "    :param dataset_name: Name of the data set.\n",
    "    :return: List of point ids.\n",
    "    \"\"\"\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    indices = [0] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        indices[i] = int(label[1])\n",
    "    return indices\n",
    "\n",
    "def make_prediction(model, dataset_name: str, export: bool = False) -> np.array:\n",
    "    \"\"\"\n",
    "    Make a prediction the given dataset using the provided model.\n",
    "\n",
    "    :model: Instance of a model with the predict method.\n",
    "    :param dataset_name: Name of the dataset.\n",
    "    :export: Whether to export the prediction into a .csv file.\n",
    "    :return: np.array of prediction vector.\n",
    "    \"\"\"\n",
    "    data = load_data(dataset_name)\n",
    "    labels = load_labels(dataset_name)\n",
    "    prediction = model.predict(data)\n",
    "    mistakes = 0\n",
    "    zeroes = 0\n",
    "    for i, label in enumerate(prediction):\n",
    "        if round(prediction[i]) == 0:\n",
    "            zeroes += 1\n",
    "        if labels[i] != round(prediction[i]):\n",
    "            mistakes += 1\n",
    "    print(f\"Made {mistakes} mistakes!\")\n",
    "    print(f\"There were total of {zeroes} zeroes!\")\n",
    "    #print(f\"Model accuracy: {model.score(data, labels)}\")\n",
    "    if export:\n",
    "        export_prediction(dataset_name, prediction)\n",
    "    return prediction\n",
    "\n",
    "def export_prediction(dataset_name: str, prediction: np.array) -> None:\n",
    "    indices = load_indices(dataset_name)\n",
    "    prediction_file = PRED_FILES_ROOT + dataset_name + \"_prediction.csv\"\n",
    "    with open(prediction_file, 'w') as file:\n",
    "        for i, point_index in enumerate(indices):\n",
    "            p = round(prediction[i])\n",
    "            print(f\"{i},{point_index},{int(p)}\", file=file)\n",
    "            \n",
    "            \n",
    "make_prediction(model_rfc, \"fruit_01\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
