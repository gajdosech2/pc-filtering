{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEnT4bZnu5jQ"
   },
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "-ZlMuBGau5ji",
    "outputId": "5da0cfb2-cb8b-4e74-b855-c6f5ee880513"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "tile_size = 19\n",
    "feature_count = 3\n",
    "input_count = tile_size * tile_size * feature_count\n",
    "DATA_FILES_ROOT = \"DataFiles/\"\n",
    "PRED_FILES_ROOT = \"Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "loading 9000. file\n",
      "loading 10000. file\n",
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "done loading datasets\n"
     ]
    }
   ],
   "source": [
    "def load_data(dataset_name: str) -> np.array:\n",
    "    data_path = DATA_FILES_ROOT + dataset_name + \"_data/\"\n",
    "    data_files = os.listdir(data_path)\n",
    "    data_array = [None] * len(data_files)\n",
    "    for i, file in enumerate(data_files):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"loading {i}. file\")\n",
    "        data = np.loadtxt(data_path + file, skiprows=1, delimiter=',')\n",
    "        data_array[i] = data.flatten()\n",
    "    return np.array(data_array)\n",
    "\n",
    "\n",
    "def load_labels(dataset_name: str) -> np.array:\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    labels_array = [None] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        labels_array[i] = label[2]\n",
    "    return np.array(labels_array)\n",
    "\n",
    "def load_datasets(datasets: list) -> (np.array, np.array):\n",
    "    data = []\n",
    "    labels = np.array([])\n",
    "    for dataset in datasets:\n",
    "        if (len(data) == 0):\n",
    "            data = load_data(dataset)\n",
    "        else:\n",
    "            data = np.concatenate((data, load_data(dataset)), axis=0)\n",
    "        labels = np.concatenate((labels, load_labels(dataset)), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "datasets = [\"fruit_02\", \"fruit_03\", \"fruit_04\"]\n",
    "data, labels = load_datasets(datasets)\n",
    "print(\"done loading datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26913, 1080)\n",
      "(26913,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.mean(data, axis=0)\n",
    "data_std = np.std(data, axis=0)\n",
    "data -= data_mean\n",
    "data /= data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "uqJeDH0Jgq3u",
    "outputId": "3c13268c-c4a7-4421-e61f-54dfdb4dee1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18839\n",
      "18561.0\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(train_X))\n",
    "print(np.sum(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhchzYAxKNou"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7ZElIFH8o63W",
    "outputId": "2c9807df-0ec1-4283-d0d6-d7a3b3fca88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train accuracy: 1.0\n",
      "Actual percentage of true points: 0.9852433780986252\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(C=1000, gamma=1/10000, kernel='rbf')\n",
    "#model_svm = svm.SVC(kernel='rbf')\n",
    "model_svm.fit(train_X, train_y)\n",
    "\n",
    "print(f\"SVM Train accuracy: {model_svm.score(train_X, train_y)}\")\n",
    "print(f\"Actual percentage of true points: {np.sum(train_y)/len(train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.99140127 0.99124204 0.9906036 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross validation scores: {cross_val_score(model_svm, train_X, train_y, cv=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SVM Test accuracy: {model_svm.score(test_X, test_y)}\")\n",
    "print(f\"Actual percentage of true points: {np.sum(test_y)/len(test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=20, max_depth=10)\n",
    "model_rfc.fit(train_X, train_y)\n",
    "\n",
    "print(f\"RFC Train accuracy: {model_svm.score(train_X, train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.99442675 0.99458599 0.99331104]\n",
      "RFC Test accuracy: 0.9946742630666336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross validation scores: {cross_val_score(model_rfc, train_X, train_y, cv=3)}\")\n",
    "print(f\"RFC Test accuracy: {model_rfc.score(test_X, test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  166   112]\n",
      " [   53 18508]]\n",
      "0.9939849624060151\n",
      "0.9971445504013793\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "train_y_svm_prediction = cross_val_predict(model_svm, train_X, train_y, cv=3)\n",
    "confusion_svm = confusion_matrix(train_y, train_y_svm_prediction)\n",
    "precision_svm = precision_score(train_y, train_y_svm_prediction)\n",
    "recall_svm = recall_score(train_y, train_y_svm_prediction)\n",
    "\n",
    "print(confusion_svm)\n",
    "print(precision_svm)\n",
    "print(recall_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  182    96]\n",
      " [    6 18555]]\n",
      "0.994852822904938\n",
      "0.9996767415548731\n"
     ]
    }
   ],
   "source": [
    "#RFC\n",
    "train_y_rfc_prediction = cross_val_predict(model_rfc, train_X, train_y, cv=3)\n",
    "confusion_rfc = confusion_matrix(train_y, train_y_rfc_prediction)\n",
    "precision_rfc = precision_score(train_y, train_y_rfc_prediction)\n",
    "recall_rfc = recall_score(train_y, train_y_rfc_prediction)\n",
    "\n",
    "print(confusion_rfc)\n",
    "print(precision_rfc)\n",
    "print(recall_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "loading 9000. file\n",
      "loading 10000. file\n",
      "loading 11000. file\n",
      "loading 12000. file\n",
      "Precision on this dataset: 0.9989469420818144\n",
      "Recall on this dataset: 0.9998378466028863\n",
      "Made 15 mistakes!\n",
      "There were total of 59 zeroes!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_indices(dataset_name: str) -> list:\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    indices = [0] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        indices[i] = int(label[1])\n",
    "    return indices\n",
    "\n",
    "def make_prediction(model, dataset_name: str, export: bool = False) -> np.array:\n",
    "    data = load_data(dataset_name)\n",
    "    data -= data_mean\n",
    "    data /= data_std\n",
    "    labels = load_labels(dataset_name)\n",
    "    prediction = model.predict(data)\n",
    "    \n",
    "    print(f\"Precision on this dataset: {precision_score(labels, prediction)}\")\n",
    "    print(f\"Recall on this dataset: {recall_score(labels, prediction)}\")\n",
    "    \n",
    "    mistakes = 0\n",
    "    zeroes = 0\n",
    "    for i, label in enumerate(prediction):\n",
    "        if round(prediction[i]) == 0:\n",
    "            zeroes += 1\n",
    "        if labels[i] != round(prediction[i]):\n",
    "            mistakes += 1\n",
    "    print(f\"Made {mistakes} mistakes!\")\n",
    "    print(f\"There were total of {zeroes} zeroes!\")\n",
    "    #print(f\"Model accuracy: {model.score(data, labels)}\")\n",
    "    if export:\n",
    "        export_prediction(dataset_name, prediction)\n",
    "    return prediction\n",
    "\n",
    "def export_prediction(dataset_name: str, prediction: np.array) -> None:\n",
    "    indices = load_indices(dataset_name)\n",
    "    prediction_file = PRED_FILES_ROOT + dataset_name + \"_prediction.csv\"\n",
    "    with open(prediction_file, 'w') as file:\n",
    "        for i, point_index in enumerate(indices):\n",
    "            p = round(prediction[i])\n",
    "            print(f\"{i},{point_index},{int(p)}\", file=file)\n",
    "            \n",
    "            \n",
    "make_prediction(model_rfc, \"fruit_01\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
