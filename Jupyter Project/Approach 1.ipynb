{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEnT4bZnu5jQ"
   },
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "-ZlMuBGau5ji",
    "outputId": "5da0cfb2-cb8b-4e74-b855-c6f5ee880513"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "tile_size = 19\n",
    "feature_count = 3\n",
    "input_count = tile_size * tile_size * feature_count\n",
    "DATA_FILES_ROOT = \"../Model/DataFiles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "loading 7000. file\n",
      "loading 8000. file\n",
      "(16115, 1080)\n",
      "(16115,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(dataset_name: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load data files for the given dataset.\n",
    "\n",
    "    :param dataset_name: Name of the data set.\n",
    "    :return: np.array of data files in (input_count, ) shape.\n",
    "    \"\"\"\n",
    "    data_path = DATA_FILES_ROOT + dataset_name + \"_data/\"\n",
    "    data_files = os.listdir(data_path)\n",
    "    data_array = [None] * len(data_files)\n",
    "    for i, file in enumerate(data_files):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"loading {i}. file\")\n",
    "        data = np.loadtxt(data_path + file, skiprows=1, delimiter=',')\n",
    "        data_array[i] = data.flatten()\n",
    "    return np.array(data_array)\n",
    "\n",
    "\n",
    "def load_labels(dataset_name: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Load data labels for the given dataset.\n",
    "\n",
    "    :param dataset_name: Name of the data set.\n",
    "    :return: np.array of the data labels.\n",
    "    \"\"\"\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    labels_array = [None] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        labels_array[i] = label[2]\n",
    "    return np.array(labels_array)\n",
    "\n",
    "def load_datasets(datasets: list) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "    Load both the input data vectors and labels of the datasets with the given names.\n",
    "\n",
    "    :param datasets: List with the dataset names.\n",
    "    :return: tuple of np.arrays, one with the input vectors, second with labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = np.array([])\n",
    "    for dataset in datasets:\n",
    "        if (len(data) == 0):\n",
    "            data = load_data(dataset)\n",
    "        else:\n",
    "            data = np.concatenate((data, load_data(dataset)), axis=0)\n",
    "        labels = np.concatenate((labels, load_labels(dataset)), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "datasets = [\"fruit_03\", \"fruit_04\"]\n",
    "data, labels = load_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16115, 1080)\n",
      "(16115,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "uqJeDH0Jgq3u",
    "outputId": "3c13268c-c4a7-4421-e61f-54dfdb4dee1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11280\n",
      "11160.0\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(train_X))\n",
    "print(np.sum(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhchzYAxKNou"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7ZElIFH8o63W",
    "outputId": "2c9807df-0ec1-4283-d0d6-d7a3b3fca88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train accuracy: 1.0\n",
      "SVM Test accuracy: 0.9950361944157187\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(C=100, gamma=1/10000, kernel='rbf')\n",
    "model_svm.fit(train_X, train_y)\n",
    "\n",
    "print(f\"SVM Train accuracy: {model_svm.score(train_X, train_y)}\")\n",
    "print(f\"SVM Test accuracy: {model_svm.score(test_X, test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877973112719752\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99308511, 0.99760638, 0.99574468])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_svm, train_X, train_y, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   84    36]\n",
      " [   15 11145]]\n",
      "0.9967802522135766\n",
      "0.9986559139784946\n"
     ]
    }
   ],
   "source": [
    "train_y_prediction = cross_val_predict(model_svm, train_X, train_y, cv=3)\n",
    "confusion = confusion_matrix(train_y, train_y_prediction)\n",
    "precision = precision_score(train_y, train_y_prediction)\n",
    "recall = recall_score(train_y, train_y_prediction)\n",
    "\n",
    "print(confusion)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0. file\n",
      "loading 1000. file\n",
      "loading 2000. file\n",
      "loading 3000. file\n",
      "loading 4000. file\n",
      "loading 5000. file\n",
      "loading 6000. file\n",
      "Made 327 mistakes!\n",
      "There were total of 360 zeroes!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_indices(dataset_name: str) -> list:\n",
    "    labels_file = DATA_FILES_ROOT + dataset_name + \"_truth.csv\"\n",
    "    labels = np.loadtxt(labels_file, delimiter=',')\n",
    "    indices = [0] * len(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        indices[i] = int(label[1])\n",
    "    return indices\n",
    "\n",
    "def make_prediction(model, dataset_name: str, export: bool = False) -> np.array:\n",
    "    data = load_data(dataset_name)\n",
    "    labels = load_labels(dataset_name)\n",
    "    prediction = model.predict(data)\n",
    "    mistakes = 0\n",
    "    zeroes = 0\n",
    "    for i, label in enumerate(prediction):\n",
    "        if round(prediction[i]) == 0:\n",
    "            zeroes += 1\n",
    "        if labels[i] != round(prediction[i]):\n",
    "            mistakes += 1\n",
    "    print(f\"Made {mistakes} mistakes!\")\n",
    "    print(f\"There were total of {zeroes} zeroes!\")\n",
    "    #print(f\"Model accuracy: {model.score(data, labels)}\")\n",
    "    if export:\n",
    "        export_prediction(dataset_name, prediction)\n",
    "    return prediction\n",
    "\n",
    "def export_prediction(dataset_name: str, prediction: np.array) -> None:\n",
    "    indices = load_indices(dataset_name)\n",
    "    prediction_file = DATA_FILES_ROOT + dataset_name + \"_prediction.csv\"\n",
    "    with open(prediction_file, 'w') as file:\n",
    "        for i, point_index in enumerate(indices):\n",
    "            p = round(prediction[i])\n",
    "            print(f\"{i},{point_index},{int(p)}\", file=file)\n",
    "            \n",
    "            \n",
    "make_prediction(model_svm, \"fruit_05\", True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
